{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "901a51d1",
   "metadata": {},
   "source": [
    "MovieLens Analysis Pipeline with DuckDB + DagsHub\n",
    "This project demonstrates how to build a generalizable, scalable, and reproducible data pipeline for exploratory analysis of the MovieLens 10M dataset, leveraging modern openâ€‘source tools and cloudâ€‘based hosting.\n",
    "\n",
    "Pipeline Steps\n",
    "- Data Extraction (.dat)\n",
    "The original MovieLens files (ratings.dat, movies.dat, tags.dat) are read directly from DagsHub URLs. DuckDBâ€™s read_csv_auto parses the \"::\" delimited files. Options like ignore_errors=true and quote='' handle malformed lines and problematic quotes.\n",
    "- Transformation to Parquet\n",
    "After ingestion, the data is converted into Parquet files: ratings.parquet, movies.parquet, tags.parquet.\n",
    "Parquet is a columnar format, which means that instead of storing data row by row, it stores it column by column. This makes analytical queries much faster, reduces disk usage through compression, and allows selective reading of only the columns needed for a query.\n",
    "- Upload to DagsHub\n",
    "The generated Parquet files are uploaded back to the remote repository on DagsHub. This ensures that the processed, optimized data is available to anyone collaborating on the project, without requiring them to repeat the extraction and transformation steps.\n",
    "- Direct Queries on Remote Parquet\n",
    "DuckDB can query Parquet files directly from DagsHub via HTTP, without downloading them locally. This means that analysis can be performed on demand, from any machine, simply by pointing to the remote file URLs.\n",
    "- Exploratory Data Analysis\n",
    "SQL queries performed include: record counts per table, rating distribution, top 10 mostâ€‘rated movies, top 10 highestâ€‘rated movies with at least 100 ratings, genre popularity, most active users, and most frequent tags.\n",
    "\n",
    "Data Structure\n",
    "- ratings: userId, movieId, rating, timestamp\n",
    "- movies: movieId, title, genres\n",
    "- tags: userId, movieId, tag, timestamp\n",
    "\n",
    "Running Queries Online\n",
    "You can run queries directly against the Parquet files hosted on DagsHub, without downloading. For example, in Python with DuckDB you can create views from the remote Parquet files and run SQL queries to retrieve insights.\n",
    "\n",
    "Advantages of Each Component\n",
    "Cloud Storage (DagsHub Data Hosting)\n",
    "- Accessibility: Data stored in the cloud can be accessed from anywhere with an internet connection, removing the need to manually copy or transfer files between machines.\n",
    "- Collaboration: Multiple team members can work on the same dataset without duplicating storage or worrying about version mismatches.\n",
    "- Versioning: DagsHub integrates with Git and DVC, so datasets can be versioned just like code, ensuring reproducibility of experiments.\n",
    "- Reliability: Cloud storage reduces the risk of data loss due to local hardware failures.\n",
    "Git\n",
    "- Version Control for Code and Notebooks: Tracks every change to scripts and Jupyter notebooks, ensuring that exploratory steps, visualizations, and analysis logic are preserved.\n",
    "- Processed Data Control: By linking processed data artifacts (such as Parquet files) to commits, Git ensures that the exact version of the data used for analysis can be reproduced.\n",
    "- Collaboration: Multiple contributors can work on the same project without overwriting each otherâ€™s work.\n",
    "DagsHub\n",
    "- Unified Platform: Combines Git, DVC, MLflow, and issue tracking in one place.\n",
    "- Data + Code Integration: Hosts both the code repository and the dataset, ensuring they stay in sync.\n",
    "- Remote Access: Provides raw file URLs that can be read directly by analytical tools like DuckDB.\n",
    "- Experiment Tracking: Supports logging and comparing experiments, making it easier to manage machine learning workflows.\n",
    "DuckDB\n",
    "- Lightweight Database: Runs inâ€‘process, meaning no server setup is required.\n",
    "- Analytical Power: Optimized for OLAP (analytical) queries, making it ideal for exploring large datasets.\n",
    "- Direct File Access: Can query Parquet, CSV, and JSON files directly, including those hosted remotely.\n",
    "- SQL Interface: Provides a familiar SQL syntax, lowering the barrier for analysts and data scientists.\n",
    "- Exploratory Analysis Advantage: Because it integrates seamlessly with notebooks, DuckDB allows interactive queries, quick aggregations, and joins across large datasets without leaving the analysis environment. This makes it perfect for iterative exploration and hypothesis testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c02a8c",
   "metadata": {},
   "source": [
    "4. Consultas diretas nos Parquets remotos\n",
    "- O DuckDB acessa os arquivos Parquet direto do link do DagsHub, sem precisar baixÃ¡-los manualmente.\n",
    "- SÃ£o criadas views (ratings, movies, tags) a partir dos Parquets remotos.\n",
    "5. AnÃ¡lise ExploratÃ³ria\n",
    "Consultas SQL realizadas:\n",
    "- Contagem de registros em cada tabela.\n",
    "- DistribuiÃ§Ã£o de notas.\n",
    "- Top 10 filmes mais avaliados.\n",
    "- Top 10 filmes com melhor mÃ©dia (mÃ­nimo 100 avaliaÃ§Ãµes).\n",
    "- Popularidade por gÃªnero.\n",
    "- UsuÃ¡rios mais ativos.\n",
    "- Tags mais frequentes.\n",
    "\n",
    "ðŸ“‚ Estrutura dos Dados\n",
    "- ratings: userId, movieId, rating, timestamp\n",
    "- movies: movieId, title, genres\n",
    "- tags: userId, movieId, tag, timestamp\n",
    "\n",
    "ðŸ–¥ï¸ Como Rodar as Consultas Online\n",
    "VocÃª pode rodar as consultas diretamente nos arquivos Parquet hospedados no DagsHub, sem precisar baixar nada.\n",
    "Exemplo em Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a7bf2",
   "metadata": {},
   "source": [
    "import duckdb\n",
    "\n",
    "base_url = \"https://dagshub.com/Matheuskcode/Big-Data-Found/raw/main/data\"\n",
    "\n",
    "files = {\n",
    "    \"ratings\": f\"{base_url}/ratings.parquet\",\n",
    "    \"movies\": f\"{base_url}/movies.parquet\",\n",
    "    \"tags\": f\"{base_url}/tags.parquet\"\n",
    "}\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "con.execute(f\"CREATE OR REPLACE VIEW ratings AS SELECT * FROM parquet_scan('{files['ratings']}')\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW movies  AS SELECT * FROM parquet_scan('{files['movies']}')\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW tags    AS SELECT * FROM parquet_scan('{files['tags']}')\")\n",
    "\n",
    "df = con.execute(\"\"\"\n",
    "    SELECT m.title, COUNT(r.rating) as n_ratings, AVG(r.rating) as avg_rating\n",
    "    FROM ratings r\n",
    "    JOIN movies m ON r.movieId = m.movieId\n",
    "    GROUP BY m.title\n",
    "    ORDER BY n_ratings DESC\n",
    "    LIMIT 5\n",
    "\"\"\").df()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6221ab",
   "metadata": {},
   "source": [
    "âœ… BenefÃ­cios do Pipeline\n",
    "â€¢ \tGeneralizÃ¡vel: qualquer pessoa pode rodar em qualquer computador, basta ter Python + DuckDB.\n",
    "â€¢ \tSem download manual: os dados sÃ£o lidos direto do DagsHub via HTTP.\n",
    "â€¢ \tEficiente: uso de Parquet acelera consultas e economiza espaÃ§o.\n",
    "â€¢ \tExploratÃ³rio: consultas SQL permitem anÃ¡lises rÃ¡pidas e flexÃ­veis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4fa759",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### ðŸ’» CÃ³digo Python (pipeline completo)\n",
    "\n",
    "```python\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. Definir URLs dos arquivos no DagsHub (.dat) ---\n",
    "base_url = \"https://dagshub.com/Matheuskcode/Big-Data-Found/raw/main/data\"\n",
    "\n",
    "files = {\n",
    "    \"ratings\": f\"{base_url}/ratings.dat\",\n",
    "    \"movies\": f\"{base_url}/movies.dat\",\n",
    "    \"tags\": f\"{base_url}/tags.dat\"\n",
    "}\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# --- 2. Ler arquivos .dat direto da URL ---\n",
    "ratings = con.execute(f\"\"\"\n",
    "    SELECT * FROM read_csv_auto('{files['ratings']}',\n",
    "        delim='::',\n",
    "        columns={{'userId':'BIGINT','movieId':'BIGINT','rating':'DOUBLE','timestamp':'BIGINT'}},\n",
    "        ignore_errors=true,\n",
    "        quote=''\n",
    "    )\n",
    "\"\"\").df()\n",
    "\n",
    "movies = con.execute(f\"\"\"\n",
    "    SELECT * FROM read_csv_auto('{files['movies']}',\n",
    "        delim='::',\n",
    "        columns={{'movieId':'BIGINT','title':'VARCHAR','genres':'VARCHAR'}},\n",
    "        ignore_errors=true,\n",
    "        quote=''\n",
    "    )\n",
    "\"\"\").df()\n",
    "\n",
    "tags = con.execute(f\"\"\"\n",
    "    SELECT * FROM read_csv_auto('{files['tags']}',\n",
    "        delim='::',\n",
    "        columns={{'userId':'BIGINT','movieId':'BIGINT','tag':'VARCHAR','timestamp':'BIGINT'}},\n",
    "        ignore_errors=true,\n",
    "        quote=''\n",
    "    )\n",
    "\"\"\").df()\n",
    "\n",
    "# --- 3. Salvar em Parquet ---\n",
    "ratings.to_parquet(\"ratings.parquet\", index=False)\n",
    "movies.to_parquet(\"movies.parquet\", index=False)\n",
    "tags.to_parquet(\"tags.parquet\", index=False)\n",
    "\n",
    "# --- 4. Upload para DagsHub (executar em notebook com dagshub-cli instalado) ---\n",
    "# !dagshub upload Matheuskcode/Big-Data-Found \"ratings.parquet\" data/ratings.parquet --update\n",
    "# !dagshub upload Matheuskcode/Big-Data-Found \"movies.parquet\" data/movies.parquet --update\n",
    "# !dagshub upload Matheuskcode/Big-Data-Found \"tags.parquet\" data/tags.parquet --update\n",
    "\n",
    "# --- 5. Consultas diretas nos Parquets remotos ---\n",
    "files_parquet = {\n",
    "    \"ratings\": f\"{base_url}/ratings.parquet\",\n",
    "    \"movies\": f\"{base_url}/movies.parquet\",\n",
    "    \"tags\": f\"{base_url}/tags.parquet\"\n",
    "}\n",
    "\n",
    "con.execute(f\"CREATE OR REPLACE VIEW ratings AS SELECT * FROM parquet_scan('{files_parquet['ratings']}')\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW movies  AS SELECT * FROM parquet_scan('{files_parquet['movies']}')\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW tags    AS SELECT * FROM parquet_scan('{files_parquet['tags']}')\")\n",
    "\n",
    "# --- 6. AnÃ¡lises ExploratÃ³rias ---\n",
    "print(\"Tamanhos:\")\n",
    "print(con.execute(\"SELECT COUNT(*) AS n_ratings FROM ratings\").df())\n",
    "print(con.execute(\"SELECT COUNT(*) AS n_movies FROM movies\").df())\n",
    "print(con.execute(\"SELECT COUNT(*) AS n_tags FROM tags\").df())\n",
    "\n",
    "print(\"\\nDistribuiÃ§Ã£o de notas:\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT rating, COUNT(*) as freq\n",
    "    FROM ratings\n",
    "    GROUP BY rating\n",
    "    ORDER BY rating\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nTop 10 filmes mais avaliados:\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT m.title, COUNT(r.rating) as n_ratings, AVG(r.rating) as avg_rating\n",
    "    FROM ratings r\n",
    "    JOIN movies m ON r.movieId = m.movieId\n",
    "    GROUP BY m.title\n",
    "    ORDER BY n_ratings DESC\n",
    "    LIMIT 10\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nTop 10 filmes com melhor mÃ©dia (>=100 avaliaÃ§Ãµes):\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT m.title, COUNT(r.rating) as n_ratings, AVG(r.rating) as avg_rating\n",
    "    FROM ratings r\n",
    "    JOIN movies m ON r.movieId = m.movieId\n",
    "    GROUP BY m.title\n",
    "    HAVING COUNT(r.rating) >= 100\n",
    "    ORDER BY avg_rating DESC\n",
    "    LIMIT 10\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nPopularidade por gÃªnero:\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT genre, COUNT(*) as n_movies\n",
    "    FROM (\n",
    "        SELECT movieId, UNNEST(STRING_SPLIT(genres, '|')) as genre\n",
    "        FROM movies\n",
    "    )\n",
    "    GROUP BY genre\n",
    "    ORDER BY n_movies DESC\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nTop 10 usuÃ¡rios mais ativos:\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT userId, COUNT(*) as n_ratings, AVG(rating) as avg_rating\n",
    "    FROM ratings\n",
    "    GROUP BY userId\n",
    "    ORDER BY n_ratings DESC\n",
    "    LIMIT 10\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nTop 10 tags mais usadas:\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT LOWER(tag) as tag, COUNT(*) as freq\n",
    "    FROM tags\n",
    "    GROUP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
