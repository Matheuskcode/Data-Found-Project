{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "901a51d1",
   "metadata": {},
   "source": [
    "# ðŸ“Š Pipeline de AnÃ¡lise do MovieLens com DuckDB + DagsHub\n",
    "\n",
    "Este projeto demonstra como construir um pipeline de dados **generalizÃ¡vel** para anÃ¡lise exploratÃ³ria do dataset **MovieLens 10M**, utilizando:\n",
    "\n",
    "- [DuckDB](https://duckdb.org/) para consultas SQL rÃ¡pidas em arquivos locais ou remotos.\n",
    "- [DagsHub](https://dagshub.com/) como repositÃ³rio de dados e cÃ³digo, permitindo acesso direto via HTTP.\n",
    "- ConversÃ£o dos arquivos originais `.dat` para o formato **Parquet**, mais eficiente e portÃ¡til.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Etapas do Pipeline\n",
    "\n",
    "### 1. ExtraÃ§Ã£o dos dados (`.dat`)\n",
    "- Os arquivos originais (`ratings.dat`, `movies.dat`, `tags.dat`) sÃ£o lidos **diretamente da URL do DagsHub**.\n",
    "- O DuckDB Ã© usado com `read_csv_auto` para interpretar os arquivos delimitados por `::`.\n",
    "- ParÃ¢metros como `ignore_errors=true` e `quote=''` foram usados para lidar com linhas problemÃ¡ticas e aspas malformadas.\n",
    "\n",
    "### 2. TransformaÃ§Ã£o para Parquet\n",
    "- ApÃ³s a leitura, os DataFrames sÃ£o convertidos e salvos em **arquivos Parquet**:\n",
    "  - `ratings.parquet`\n",
    "  - `movies.parquet`\n",
    "  - `tags.parquet`\n",
    "- O Parquet Ã© colunar, ocupa menos espaÃ§o e Ã© muito mais rÃ¡pido para consultas.\n",
    "\n",
    "### 3. Upload para o DagsHub\n",
    "- Os Parquets gerados sÃ£o enviados de volta para o repositÃ³rio remoto no DagsHub com:\n",
    "  ```bash\n",
    "  !dagshub upload Matheuskcode/Big-Data-Found \"ratings.parquet\" data/ratings.parquet --update\n",
    "  !dagshub upload Matheuskcode/Big-Data-Found \"movies.parquet\" data/movies.parquet --update\n",
    "  !dagshub upload Matheuskcode/Big-Data-Found \"tags.parquet\" data/tags.parquet --update\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c02a8c",
   "metadata": {},
   "source": [
    "4. Consultas diretas nos Parquets remotos\n",
    "- O DuckDB acessa os arquivos Parquet direto do link do DagsHub, sem precisar baixÃ¡-los manualmente.\n",
    "- SÃ£o criadas views (ratings, movies, tags) a partir dos Parquets remotos.\n",
    "5. AnÃ¡lise ExploratÃ³ria\n",
    "Consultas SQL realizadas:\n",
    "- Contagem de registros em cada tabela.\n",
    "- DistribuiÃ§Ã£o de notas.\n",
    "- Top 10 filmes mais avaliados.\n",
    "- Top 10 filmes com melhor mÃ©dia (mÃ­nimo 100 avaliaÃ§Ãµes).\n",
    "- Popularidade por gÃªnero.\n",
    "- UsuÃ¡rios mais ativos.\n",
    "- Tags mais frequentes.\n",
    "\n",
    "ðŸ“‚ Estrutura dos Dados\n",
    "- ratings: userId, movieId, rating, timestamp\n",
    "- movies: movieId, title, genres\n",
    "- tags: userId, movieId, tag, timestamp\n",
    "\n",
    "ðŸ–¥ï¸ Como Rodar as Consultas Online\n",
    "VocÃª pode rodar as consultas diretamente nos arquivos Parquet hospedados no DagsHub, sem precisar baixar nada.\n",
    "Exemplo em Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a7bf2",
   "metadata": {},
   "source": [
    "import duckdb\n",
    "\n",
    "base_url = \"https://dagshub.com/Matheuskcode/Big-Data-Found/raw/main/data\"\n",
    "\n",
    "files = {\n",
    "    \"ratings\": f\"{base_url}/ratings.parquet\",\n",
    "    \"movies\": f\"{base_url}/movies.parquet\",\n",
    "    \"tags\": f\"{base_url}/tags.parquet\"\n",
    "}\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "con.execute(f\"CREATE OR REPLACE VIEW ratings AS SELECT * FROM parquet_scan('{files['ratings']}')\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW movies  AS SELECT * FROM parquet_scan('{files['movies']}')\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW tags    AS SELECT * FROM parquet_scan('{files['tags']}')\")\n",
    "\n",
    "df = con.execute(\"\"\"\n",
    "    SELECT m.title, COUNT(r.rating) as n_ratings, AVG(r.rating) as avg_rating\n",
    "    FROM ratings r\n",
    "    JOIN movies m ON r.movieId = m.movieId\n",
    "    GROUP BY m.title\n",
    "    ORDER BY n_ratings DESC\n",
    "    LIMIT 5\n",
    "\"\"\").df()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6221ab",
   "metadata": {},
   "source": [
    "âœ… BenefÃ­cios do Pipeline\n",
    "â€¢ \tGeneralizÃ¡vel: qualquer pessoa pode rodar em qualquer computador, basta ter Python + DuckDB.\n",
    "â€¢ \tSem download manual: os dados sÃ£o lidos direto do DagsHub via HTTP.\n",
    "â€¢ \tEficiente: uso de Parquet acelera consultas e economiza espaÃ§o.\n",
    "â€¢ \tExploratÃ³rio: consultas SQL permitem anÃ¡lises rÃ¡pidas e flexÃ­veis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4fa759",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### ðŸ’» CÃ³digo Python (pipeline completo)\n",
    "\n",
    "```python\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. Definir URLs dos arquivos no DagsHub (.dat) ---\n",
    "base_url = \"https://dagshub.com/Matheuskcode/Big-Data-Found/raw/main/data\"\n",
    "\n",
    "files = {\n",
    "    \"ratings\": f\"{base_url}/ratings.dat\",\n",
    "    \"movies\": f\"{base_url}/movies.dat\",\n",
    "    \"tags\": f\"{base_url}/tags.dat\"\n",
    "}\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# --- 2. Ler arquivos .dat direto da URL ---\n",
    "ratings = con.execute(f\"\"\"\n",
    "    SELECT * FROM read_csv_auto('{files['ratings']}',\n",
    "        delim='::',\n",
    "        columns={{'userId':'BIGINT','movieId':'BIGINT','rating':'DOUBLE','timestamp':'BIGINT'}},\n",
    "        ignore_errors=true,\n",
    "        quote=''\n",
    "    )\n",
    "\"\"\").df()\n",
    "\n",
    "movies = con.execute(f\"\"\"\n",
    "    SELECT * FROM read_csv_auto('{files['movies']}',\n",
    "        delim='::',\n",
    "        columns={{'movieId':'BIGINT','title':'VARCHAR','genres':'VARCHAR'}},\n",
    "        ignore_errors=true,\n",
    "        quote=''\n",
    "    )\n",
    "\"\"\").df()\n",
    "\n",
    "tags = con.execute(f\"\"\"\n",
    "    SELECT * FROM read_csv_auto('{files['tags']}',\n",
    "        delim='::',\n",
    "        columns={{'userId':'BIGINT','movieId':'BIGINT','tag':'VARCHAR','timestamp':'BIGINT'}},\n",
    "        ignore_errors=true,\n",
    "        quote=''\n",
    "    )\n",
    "\"\"\").df()\n",
    "\n",
    "# --- 3. Salvar em Parquet ---\n",
    "ratings.to_parquet(\"ratings.parquet\", index=False)\n",
    "movies.to_parquet(\"movies.parquet\", index=False)\n",
    "tags.to_parquet(\"tags.parquet\", index=False)\n",
    "\n",
    "# --- 4. Upload para DagsHub (executar em notebook com dagshub-cli instalado) ---\n",
    "# !dagshub upload Matheuskcode/Big-Data-Found \"ratings.parquet\" data/ratings.parquet --update\n",
    "# !dagshub upload Matheuskcode/Big-Data-Found \"movies.parquet\" data/movies.parquet --update\n",
    "# !dagshub upload Matheuskcode/Big-Data-Found \"tags.parquet\" data/tags.parquet --update\n",
    "\n",
    "# --- 5. Consultas diretas nos Parquets remotos ---\n",
    "files_parquet = {\n",
    "    \"ratings\": f\"{base_url}/ratings.parquet\",\n",
    "    \"movies\": f\"{base_url}/movies.parquet\",\n",
    "    \"tags\": f\"{base_url}/tags.parquet\"\n",
    "}\n",
    "\n",
    "con.execute(f\"CREATE OR REPLACE VIEW ratings AS SELECT * FROM parquet_scan('{files_parquet['ratings']}')\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW movies  AS SELECT * FROM parquet_scan('{files_parquet['movies']}')\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW tags    AS SELECT * FROM parquet_scan('{files_parquet['tags']}')\")\n",
    "\n",
    "# --- 6. AnÃ¡lises ExploratÃ³rias ---\n",
    "print(\"Tamanhos:\")\n",
    "print(con.execute(\"SELECT COUNT(*) AS n_ratings FROM ratings\").df())\n",
    "print(con.execute(\"SELECT COUNT(*) AS n_movies FROM movies\").df())\n",
    "print(con.execute(\"SELECT COUNT(*) AS n_tags FROM tags\").df())\n",
    "\n",
    "print(\"\\nDistribuiÃ§Ã£o de notas:\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT rating, COUNT(*) as freq\n",
    "    FROM ratings\n",
    "    GROUP BY rating\n",
    "    ORDER BY rating\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nTop 10 filmes mais avaliados:\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT m.title, COUNT(r.rating) as n_ratings, AVG(r.rating) as avg_rating\n",
    "    FROM ratings r\n",
    "    JOIN movies m ON r.movieId = m.movieId\n",
    "    GROUP BY m.title\n",
    "    ORDER BY n_ratings DESC\n",
    "    LIMIT 10\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nTop 10 filmes com melhor mÃ©dia (>=100 avaliaÃ§Ãµes):\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT m.title, COUNT(r.rating) as n_ratings, AVG(r.rating) as avg_rating\n",
    "    FROM ratings r\n",
    "    JOIN movies m ON r.movieId = m.movieId\n",
    "    GROUP BY m.title\n",
    "    HAVING COUNT(r.rating) >= 100\n",
    "    ORDER BY avg_rating DESC\n",
    "    LIMIT 10\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nPopularidade por gÃªnero:\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT genre, COUNT(*) as n_movies\n",
    "    FROM (\n",
    "        SELECT movieId, UNNEST(STRING_SPLIT(genres, '|')) as genre\n",
    "        FROM movies\n",
    "    )\n",
    "    GROUP BY genre\n",
    "    ORDER BY n_movies DESC\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nTop 10 usuÃ¡rios mais ativos:\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT userId, COUNT(*) as n_ratings, AVG(rating) as avg_rating\n",
    "    FROM ratings\n",
    "    GROUP BY userId\n",
    "    ORDER BY n_ratings DESC\n",
    "    LIMIT 10\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nTop 10 tags mais usadas:\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT LOWER(tag) as tag, COUNT(*) as freq\n",
    "    FROM tags\n",
    "    GROUP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
