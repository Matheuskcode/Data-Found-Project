{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "901a51d1",
   "metadata": {},
   "source": [
    "# 📊 Pipeline de Análise do MovieLens com DuckDB + DagsHub\n",
    "\n",
    "Este projeto demonstra como construir um pipeline de dados **generalizável** para análise exploratória do dataset **MovieLens 10M**, utilizando:\n",
    "\n",
    "- [DuckDB](https://duckdb.org/) para consultas SQL rápidas em arquivos locais ou remotos.\n",
    "- [DagsHub](https://dagshub.com/) como repositório de dados e código, permitindo acesso direto via HTTP.\n",
    "- Conversão dos arquivos originais `.dat` para o formato **Parquet**, mais eficiente e portátil.\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Etapas do Pipeline\n",
    "\n",
    "### 1. Extração dos dados (`.dat`)\n",
    "- Os arquivos originais (`ratings.dat`, `movies.dat`, `tags.dat`) são lidos **diretamente da URL do DagsHub**.\n",
    "- O DuckDB é usado com `read_csv_auto` para interpretar os arquivos delimitados por `::`.\n",
    "- Parâmetros como `ignore_errors=true` e `quote=''` foram usados para lidar com linhas problemáticas e aspas malformadas.\n",
    "\n",
    "### 2. Transformação para Parquet\n",
    "- Após a leitura, os DataFrames são convertidos e salvos em **arquivos Parquet**:\n",
    "  - `ratings.parquet`\n",
    "  - `movies.parquet`\n",
    "  - `tags.parquet`\n",
    "- O Parquet é colunar, ocupa menos espaço e é muito mais rápido para consultas.\n",
    "\n",
    "### 3. Upload para o DagsHub\n",
    "- Os Parquets gerados são enviados de volta para o repositório remoto no DagsHub com:\n",
    "  ```bash\n",
    "  !dagshub upload Matheuskcode/Big-Data-Found \"ratings.parquet\" data/ratings.parquet --update\n",
    "  !dagshub upload Matheuskcode/Big-Data-Found \"movies.parquet\" data/movies.parquet --update\n",
    "  !dagshub upload Matheuskcode/Big-Data-Found \"tags.parquet\" data/tags.parquet --update\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c02a8c",
   "metadata": {},
   "source": [
    "4. Consultas diretas nos Parquets remotos\n",
    "- O DuckDB acessa os arquivos Parquet direto do link do DagsHub, sem precisar baixá-los manualmente.\n",
    "- São criadas views (ratings, movies, tags) a partir dos Parquets remotos.\n",
    "5. Análise Exploratória\n",
    "Consultas SQL realizadas:\n",
    "- Contagem de registros em cada tabela.\n",
    "- Distribuição de notas.\n",
    "- Top 10 filmes mais avaliados.\n",
    "- Top 10 filmes com melhor média (mínimo 100 avaliações).\n",
    "- Popularidade por gênero.\n",
    "- Usuários mais ativos.\n",
    "- Tags mais frequentes.\n",
    "\n",
    "📂 Estrutura dos Dados\n",
    "- ratings: userId, movieId, rating, timestamp\n",
    "- movies: movieId, title, genres\n",
    "- tags: userId, movieId, tag, timestamp\n",
    "\n",
    "🖥️ Como Rodar as Consultas Online\n",
    "Você pode rodar as consultas diretamente nos arquivos Parquet hospedados no DagsHub, sem precisar baixar nada.\n",
    "Exemplo em Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a7bf2",
   "metadata": {},
   "source": [
    "import duckdb\n",
    "\n",
    "base_url = \"https://dagshub.com/Matheuskcode/Big-Data-Found/raw/main/data\"\n",
    "\n",
    "files = {\n",
    "    \"ratings\": f\"{base_url}/ratings.parquet\",\n",
    "    \"movies\": f\"{base_url}/movies.parquet\",\n",
    "    \"tags\": f\"{base_url}/tags.parquet\"\n",
    "}\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "con.execute(f\"CREATE OR REPLACE VIEW ratings AS SELECT * FROM parquet_scan('{files['ratings']}')\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW movies  AS SELECT * FROM parquet_scan('{files['movies']}')\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW tags    AS SELECT * FROM parquet_scan('{files['tags']}')\")\n",
    "\n",
    "df = con.execute(\"\"\"\n",
    "    SELECT m.title, COUNT(r.rating) as n_ratings, AVG(r.rating) as avg_rating\n",
    "    FROM ratings r\n",
    "    JOIN movies m ON r.movieId = m.movieId\n",
    "    GROUP BY m.title\n",
    "    ORDER BY n_ratings DESC\n",
    "    LIMIT 5\n",
    "\"\"\").df()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6221ab",
   "metadata": {},
   "source": [
    "✅ Benefícios do Pipeline\n",
    "• \tGeneralizável: qualquer pessoa pode rodar em qualquer computador, basta ter Python + DuckDB.\n",
    "• \tSem download manual: os dados são lidos direto do DagsHub via HTTP.\n",
    "• \tEficiente: uso de Parquet acelera consultas e economiza espaço.\n",
    "• \tExploratório: consultas SQL permitem análises rápidas e flexíveis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4fa759",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 💻 Código Python (pipeline completo)\n",
    "\n",
    "```python\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. Definir URLs dos arquivos no DagsHub (.dat) ---\n",
    "base_url = \"https://dagshub.com/Matheuskcode/Big-Data-Found/raw/main/data\"\n",
    "\n",
    "files = {\n",
    "    \"ratings\": f\"{base_url}/ratings.dat\",\n",
    "    \"movies\": f\"{base_url}/movies.dat\",\n",
    "    \"tags\": f\"{base_url}/tags.dat\"\n",
    "}\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# --- 2. Ler arquivos .dat direto da URL ---\n",
    "ratings = con.execute(f\"\"\"\n",
    "    SELECT * FROM read_csv_auto('{files['ratings']}',\n",
    "        delim='::',\n",
    "        columns={{'userId':'BIGINT','movieId':'BIGINT','rating':'DOUBLE','timestamp':'BIGINT'}},\n",
    "        ignore_errors=true,\n",
    "        quote=''\n",
    "    )\n",
    "\"\"\").df()\n",
    "\n",
    "movies = con.execute(f\"\"\"\n",
    "    SELECT * FROM read_csv_auto('{files['movies']}',\n",
    "        delim='::',\n",
    "        columns={{'movieId':'BIGINT','title':'VARCHAR','genres':'VARCHAR'}},\n",
    "        ignore_errors=true,\n",
    "        quote=''\n",
    "    )\n",
    "\"\"\").df()\n",
    "\n",
    "tags = con.execute(f\"\"\"\n",
    "    SELECT * FROM read_csv_auto('{files['tags']}',\n",
    "        delim='::',\n",
    "        columns={{'userId':'BIGINT','movieId':'BIGINT','tag':'VARCHAR','timestamp':'BIGINT'}},\n",
    "        ignore_errors=true,\n",
    "        quote=''\n",
    "    )\n",
    "\"\"\").df()\n",
    "\n",
    "# --- 3. Salvar em Parquet ---\n",
    "ratings.to_parquet(\"ratings.parquet\", index=False)\n",
    "movies.to_parquet(\"movies.parquet\", index=False)\n",
    "tags.to_parquet(\"tags.parquet\", index=False)\n",
    "\n",
    "# --- 4. Upload para DagsHub (executar em notebook com dagshub-cli instalado) ---\n",
    "# !dagshub upload Matheuskcode/Big-Data-Found \"ratings.parquet\" data/ratings.parquet --update\n",
    "# !dagshub upload Matheuskcode/Big-Data-Found \"movies.parquet\" data/movies.parquet --update\n",
    "# !dagshub upload Matheuskcode/Big-Data-Found \"tags.parquet\" data/tags.parquet --update\n",
    "\n",
    "# --- 5. Consultas diretas nos Parquets remotos ---\n",
    "files_parquet = {\n",
    "    \"ratings\": f\"{base_url}/ratings.parquet\",\n",
    "    \"movies\": f\"{base_url}/movies.parquet\",\n",
    "    \"tags\": f\"{base_url}/tags.parquet\"\n",
    "}\n",
    "\n",
    "con.execute(f\"CREATE OR REPLACE VIEW ratings AS SELECT * FROM parquet_scan('{files_parquet['ratings']}')\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW movies  AS SELECT * FROM parquet_scan('{files_parquet['movies']}')\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW tags    AS SELECT * FROM parquet_scan('{files_parquet['tags']}')\")\n",
    "\n",
    "# --- 6. Análises Exploratórias ---\n",
    "print(\"Tamanhos:\")\n",
    "print(con.execute(\"SELECT COUNT(*) AS n_ratings FROM ratings\").df())\n",
    "print(con.execute(\"SELECT COUNT(*) AS n_movies FROM movies\").df())\n",
    "print(con.execute(\"SELECT COUNT(*) AS n_tags FROM tags\").df())\n",
    "\n",
    "print(\"\\nDistribuição de notas:\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT rating, COUNT(*) as freq\n",
    "    FROM ratings\n",
    "    GROUP BY rating\n",
    "    ORDER BY rating\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nTop 10 filmes mais avaliados:\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT m.title, COUNT(r.rating) as n_ratings, AVG(r.rating) as avg_rating\n",
    "    FROM ratings r\n",
    "    JOIN movies m ON r.movieId = m.movieId\n",
    "    GROUP BY m.title\n",
    "    ORDER BY n_ratings DESC\n",
    "    LIMIT 10\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nTop 10 filmes com melhor média (>=100 avaliações):\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT m.title, COUNT(r.rating) as n_ratings, AVG(r.rating) as avg_rating\n",
    "    FROM ratings r\n",
    "    JOIN movies m ON r.movieId = m.movieId\n",
    "    GROUP BY m.title\n",
    "    HAVING COUNT(r.rating) >= 100\n",
    "    ORDER BY avg_rating DESC\n",
    "    LIMIT 10\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nPopularidade por gênero:\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT genre, COUNT(*) as n_movies\n",
    "    FROM (\n",
    "        SELECT movieId, UNNEST(STRING_SPLIT(genres, '|')) as genre\n",
    "        FROM movies\n",
    "    )\n",
    "    GROUP BY genre\n",
    "    ORDER BY n_movies DESC\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nTop 10 usuários mais ativos:\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT userId, COUNT(*) as n_ratings, AVG(rating) as avg_rating\n",
    "    FROM ratings\n",
    "    GROUP BY userId\n",
    "    ORDER BY n_ratings DESC\n",
    "    LIMIT 10\n",
    "\"\"\").df())\n",
    "\n",
    "print(\"\\nTop 10 tags mais usadas:\")\n",
    "print(con.execute(\"\"\"\n",
    "    SELECT LOWER(tag) as tag, COUNT(*) as freq\n",
    "    FROM tags\n",
    "    GROUP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
